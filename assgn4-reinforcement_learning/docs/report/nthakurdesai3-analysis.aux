\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}MDP Problems}{1}{section.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Overview of algorithms}{1}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Value iteration}{1}{subsection.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Chosen MDPs\relax }}{2}{figure.caption.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:mdp-viz}{{1}{2}{Chosen MDPs\relax }{figure.caption.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Policy iteration}{2}{subsection.2.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Q-learning}{2}{subsection.2.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Policies and penalties for the small MDP\relax }}{3}{figure.caption.2}}
\newlabel{fig:mdp-viz-small}{{2}{3}{Policies and penalties for the small MDP\relax }{figure.caption.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Experiment and analysis}{3}{section.3}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Performance of value iteration and policy iteration\relax }}{3}{table.caption.4}}
\newlabel{tab:performance}{{1}{3}{Performance of value iteration and policy iteration\relax }{table.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Policies and penalties for the large MDP\relax }}{4}{figure.caption.3}}
\newlabel{fig:mdp-viz-big}{{3}{4}{Policies and penalties for the large MDP\relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Value iteration: policies and values after different iterations for small MDP\relax }}{5}{figure.caption.5}}
\newlabel{fig:mdp-vi-iter-small}{{4}{5}{Value iteration: policies and values after different iterations for small MDP\relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Policy iteration: policies and values after different iterations for small MDP\relax }}{5}{figure.caption.6}}
\newlabel{fig:mdp-pi-iter-small}{{5}{5}{Policy iteration: policies and values after different iterations for small MDP\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Value iteration: policies and values after different iterations for large MDP\relax }}{6}{figure.caption.7}}
\newlabel{fig:mdp-vi-iter-large}{{6}{6}{Value iteration: policies and values after different iterations for large MDP\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Policy iteration: policies and values after different iterations for large MDP\relax }}{6}{figure.caption.8}}
\newlabel{fig:mdp-pi-iter-large}{{7}{6}{Policy iteration: policies and values after different iterations for large MDP\relax }{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Q-learning: policies and Q values for small MDP\relax }}{7}{figure.caption.9}}
\newlabel{fig:mdp-ql-small}{{8}{7}{Q-learning: policies and Q values for small MDP\relax }{figure.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Q-learning: policies for large MDP\relax }}{8}{figure.caption.10}}
\newlabel{fig:mdp-ql-large}{{9}{8}{Q-learning: policies for large MDP\relax }{figure.caption.10}{}}
